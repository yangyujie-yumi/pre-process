{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori 算法原理\n",
    "\n",
    "关联规则的挖掘是一个两步的过程：\n",
    "\n",
    "1. 找出所有的频繁项集：根据相对支持度，置信度的定义可知，任意两个实体之间如果存在强关联规则，那么一定存在于频繁项集之中，反之，如果这两个实体不存在于频繁项集，则一定不会产生强关联规则\n",
    "\n",
    "2. 由频繁项集产生强关联规则：计算支持度和置信度，找到实体间的强规则\n",
    "\n",
    "**定理1**：先验性质：频繁项集的所有非空子集也一定是频繁的。\n",
    "\n",
    "**定理2**：反单调性：一个项集，如果有至少一个非空子集是非频繁的，那么这个项集一定是非频繁的。\n",
    "\n",
    "**定理3**：任何频繁k项集都是由频繁k−1项集组合生成的\n",
    "\n",
    "**定理4**：频繁k项集的所有k−1项子集一定全部都是频繁k−1项集\n",
    "\n",
    "\n",
    "\n",
    "### Reference: \n",
    "\n",
    "机器学习：Apriori算法（实践篇），https://blog.csdn.net/qq_43634001/article/details/93367907\n",
    "\n",
    "Apriori算法解析， https://blog.csdn.net/guoziqing506/article/details/60882713\n",
    "\n",
    "\n",
    "\n",
    "### 算法的实现步骤\n",
    "（1）算法（大方面）的实现步骤：\n",
    "\n",
    "- 找出所有频繁项集\n",
    "- 由频繁项集产生强关联规则\n",
    "\n",
    "（2）挖掘频繁项集的步骤：\n",
    "\n",
    "- 先搜索出候选 1 项集及对应的支持度，剪枝去掉低于最小支持度的项集，得到频繁 1 项集。\n",
    "- 搜索出候选 2 项集及对应的支持度，再剪枝去掉低于最小支持度的项集，得到频繁 2 项集。\n",
    "- 以此类推，一直迭代下取，直到频繁 k+1 项集位置。对应的 k 项集即为算法的输出结果。\n",
    "\n",
    "\n",
    "（3）由频繁项集产生关联规则的步骤：\n",
    "\n",
    "- 对于每个频繁项集，产生该项集的所有非空子集（这些非空子集一定是频繁项集）\n",
    "- 对于每一个非空子集，如果 confidence(A=>B)>=confmin（最小置信度）则输出 A=>B。称为强关联规则。\n",
    "\n",
    "\n",
    "### 函数的功能说明\n",
    "\n",
    "1. `loadDataSet()`：读入数据，并将数据转换成数字\n",
    "2. `createC1()`: 构建初始候选项集的列表，即所有候选集只包含一个元素\n",
    "3. `scanD()`:计算 Ck 中项集在数据集的支持度，返回满足最小支持度的集合和所有支持度信息的字典\n",
    "4. `aprioriGen()`:由初始候选集的集合生成新的候选集，k参数表示生成新项集中所含有的元素的个数\n",
    "5. `apriori()`: Apriori 算法重要函数，重要目的是返回所有满足条件的频繁项集的列表和所有选项集的支持度信息。\n",
    "6. `generateRules()`:根据频繁项集和最小可信度生成规则\n",
    "7. `calcConf()`:计算规则的可信度，返回满足最小可信度的规则\n",
    "\n",
    "### 所用数据集：\n",
    "\n",
    "1. 网址：http://archive.ics.uci.edu/ml/index.php\n",
    "2. 内容：mushroom 数据集, http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "### 数据集说明：\n",
    "\n",
    "该数据集包括与23种菌类（the Agaricus and Lepiota Family (pp. 500-525)）相对应的假设样本的描述。每种被鉴定为绝对可食用、绝对有毒、或未知食用性、不推荐。后一类与有毒的结合在一起。指南明确指出，确定蘑菇的食用性没有简单的规则；对于有毒的橡树(Oak)和常春藤(Ivy)，没有类似“leaflets three, let it be”的规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')   #忽略警告\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    #读入文件\n",
    "    dataSet = pd.read_csv('./datasets/apriori/agaricus-lepiota.data', ',', header=None)\n",
    "    #加上列名，便于操作\n",
    "    dataSet = pd.DataFrame(data=np.array(dataSet),columns=['classes', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape','stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat'], index=range(8124))\n",
    "\n",
    "    model_label01 = dataSet[\"classes\"].replace({\"e\": '1', \"p\":'2' })\n",
    "    model_label02 = dataSet[\"cap-shape\"].replace({\"b\":'3', \"c\":'4', \"x\":'5', \"f\":'6', \"k\":'7', \"s\":'8'})\n",
    "    model_label03 = dataSet[\"cap-surface\"].replace({\"f\":'9', \"g\":'10', \"y\":'11', \"s\":'12'})\n",
    "    model_label04 =  dataSet[\"cap-color\"].replace({\"n\":'13', \"b\":'14', \"c\":'15', \"g\":'16', \"r\":'17', \"p\":'18', \"u\":'19', \"e\":'20', \"w\":'21', \"y\":'22'})\n",
    "    model_label05 =  dataSet[\"bruises\"].replace({\"t\":'23', \"f\":'24'})\n",
    "    model_label06 =  dataSet[\"odor\"].replace({\"a\":'25', \"l\":'26', \"c\":'27', \"y\":'28', \"f\":'29', \"m\":'30', \"n\":'31', \"p\":'32', \"s\":'33'})\n",
    "    model_label07 =  dataSet['gill-attachment'].replace({\"a\":'34', \"d\":'35', \"f\":'36', \"n\":'37'})\n",
    "    model_label08 =  dataSet[\"gill-spacing\"].replace({\"c\":'38', \"w\":'39', \"d\":'40'})\n",
    "    model_label09 =  dataSet[\"gill-size\"].replace({\"b\":'41', \"n\":'42'})\n",
    "    model_label10 =  dataSet[\"gill-color\"].replace({\"k\":'43', \"n\":'44', \"b\":'45', \"h\":'46', \"g\":'47', \"r\":'48', \"o\":'49', \"p\":'50', \"u\":'51', \"e\":'52', \"w\":'53', \"y\":'54'})\n",
    "    model_label11 =  dataSet['stalk-shape'].replace({\"e\":'55', \"t\":'56'})\n",
    "    model_label12 =  dataSet[\"stalk-root\"].replace({\"b\":'57', \"c\":'58', \"u\":'59', \"e\":'60', \"z\":'61', \"r\":'62', \"?\":'63'})\n",
    "    model_label13 =  dataSet[\"stalk-surface-above-ring\"].replace({\"f\":'64', \"y\":'65', \"k\":'66', \"s\":'67'})\n",
    "    model_label14 =  dataSet[\"stalk-surface-below-ring\"].replace({\"f\": '68', \"y\": '69', \"k\": '70', \"s\": '71'})\n",
    "    model_label15 =  dataSet[\"stalk-color-above-ring\"].replace({\"n\":'72', \"b\":'73', \"c\":'74', \"g\":'75', \"o\":'76', \"p\":'77', \"e\":'78', \"w\":'79', \"y\":'80'})\n",
    "    model_label16 =  dataSet[\"stalk-color-above-ring\"].replace({\"n\": '81', \"b\": '82', \"c\": '83', \"g\": '84', \"o\": '85', \"p\": '86', \"e\": '87', \"w\": '88', \"y\": '89'})\n",
    "    model_label17 =  dataSet[\"veil-type\"].replace({\"p\":'90', \"u\":'91'})\n",
    "    model_label18 =  dataSet[\"veil-color\"].replace({\"n\":'92', \"o\":'93', \"w\":'94', \"y\":'95'})\n",
    "    model_label19 =  dataSet[\"ring-number\"].replace({\"n\":'96', \"o\":'97', \"t\":'98'})\n",
    "    model_label20 =  dataSet[\"ring-type\"].replace({\"c\":'99', \"e\":'100', \"f\":'101', \"l\":'102', \"n\":'103', \"p\":'104', \"s\":'105', \"z\":'106'})\n",
    "    model_label21 =  dataSet[\"spore-print-color\"].replace({\"k\":'107', \"n\":'108', \"b\":'109', \"h\":'110', \"r\":'101', \"o\":'102', \"u\":'103', \"w\":'104', \"y\":'105'})\n",
    "    model_label22 =  dataSet[\"population\"].replace({\"a\":'106', \"c\":'107', \"n\":'108', \"s\":'109', \"v\":'110', \"y\":'111'})\n",
    "    model_label23 =  dataSet[\"habitat\"].replace({\"g\":'112', \"l\":'113', \"m\":'114', \"p\":'115', \"u\":'116', \"w\":'117', \"d\":'118'})\n",
    "    model_label = pd.concat([model_label01, model_label02, model_label03, model_label04, model_label05, model_label06, model_label07, model_label08, model_label09, model_label10, model_label11, model_label12, model_label13, model_label14, model_label15, model_label16, model_label17, model_label18, model_label19, model_label20, model_label21, model_label22, model_label23],axis = 1,  ignore_index=False)\n",
    "    return model_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    \"\"\"\n",
    "    构建初始候选项集的列表，即所有候选项集只包含一个元素，\n",
    "    C1是大小为1的所有候选项集的集合\n",
    "    :param dataSet:数据集\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #定义候选集列表C1\n",
    "    C1 = []\n",
    "    #遍历数据集合，并且遍历每一个集合中的每一项，创建只包含一个元素的候选项集集合\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            # 如果没有在C1列表中，则将该项的列表形式添加进去\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    # 对列表进行排序\n",
    "    C1.sort()\n",
    "    # 固定列表C1，使其不可变\n",
    "    return list(map(frozenset, C1))\n",
    "\n",
    "def scanD(D,Ck,minSupport):\n",
    "    \"\"\"\n",
    "    函数说明:创建满足支持度要求的候选键集合\n",
    "    \"\"\"\n",
    "    # 定义存储每个项集在消费记录中出现的次数的字典\n",
    "    ssCnt={}\n",
    "    # 遍历这个数据集，并且遍历候选项集集合，判断候选项是否是一条记录的子集\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                # 如果是则累加其出现的次数\n",
    "                if not can in ssCnt:\n",
    "                    ssCnt[can]=1\n",
    "                else: ssCnt[can]+=1\n",
    "    # 计算数据集总及记录数\n",
    "    numItems=float(len(D))\n",
    "    # 定义满足最小支持度的候选项集列表\n",
    "    retList = []\n",
    "    # 用于所有项集的支持度\n",
    "    supportData = {}\n",
    "    # 遍历整个字典\n",
    "    for key in ssCnt:\n",
    "        # 计算当前项集的支持度\n",
    "        support = ssCnt[key]/numItems\n",
    "        # 如果该项集支持度大于最小要求，则将其头插至L1列表中\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0,key)\n",
    "        # 记录每个项集的支持度\n",
    "        supportData[key] = support\n",
    "    return retList, supportData\n",
    "\n",
    "def aprioriGen(Lk, k):\n",
    "    \"\"\"\n",
    "    函数说明：#上述函数创建了L1，则现在需要创建由L1->C2的函数，也就是说需要将每个项集集合元素加1\n",
    "    :param Lk: 频繁项集列表\n",
    "    :param k: 项集元素个数\n",
    "    \"\"\"\n",
    "    # 存储Ck的列表\n",
    "    retList = []\n",
    "    # 获取lkPri长度，便于在其中遍历\n",
    "    lenLk = len(Lk)\n",
    "    # 两两遍历候选项集中的集合\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            # 因为列表元素为集合，所以在比较前需要先将其转换为list,选择集合中前k-2个元素进行比较，如果相等，则对两个集合进行并操作\n",
    "            # 这里可以保证减少遍历次数，并且可保证集合元素比合并前增加一个\n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]\n",
    "            # 对转化后的列表进行排序，便于比较\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1==L2: #若两个集合的前k-2个项相同时,则将两个集合合并\n",
    "                retList.append(Lk[i] | Lk[j]) #set union\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataSet, minSupport = 0.5):\n",
    "    \"\"\"\n",
    "    函数说明：生成所有频繁项集函数\n",
    "    \"\"\"\n",
    "    # 创建C1\n",
    "    C1 = createC1(dataSet)\n",
    "    # 对数据集进行转换，并调用函数筛选出满足条件的项集\n",
    "    D = list(map(set, dataSet))\n",
    "    L1, supportData = scanD(D, C1, minSupport)#单项最小支持度判断 0.5，生成L1\n",
    "    # 定义存储所有频繁项集的列表\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    # 迭代开始，生成所有满足条件的频繁项集（每次迭代项集元素个数加1）\n",
    "    # 迭代停止条件为，当频繁项集中包含了所有单个项集元素后停止\n",
    "    while (len(L[k-2]) > 0):#创建包含更大项集的更大列表,直到下一个大的项集为空\n",
    "        Ck = aprioriGen(L[k-2], k)#Ck\n",
    "        Lk, supK = scanD(D, Ck, minSupport)\n",
    "        supportData.update(supK)\n",
    "        # 更新supportData\n",
    "        # 不断的添加以项集为key，以项集的支持度为value的元素\n",
    "        # 将此次迭代产生的频繁集集合加入L中\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData\n",
    "\n",
    "#生成关联规则\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    #频繁项集列表、包含那些频繁项集支持数据的字典、最小可信度阈值\n",
    "    bigRuleList = [] #存储所有的关联规则\n",
    "    for i in range(1, len(L)):  #只获取有两个或者更多集合的项目，从1,即第二个元素开始，L[0]是单个元素的\n",
    "        # 两个及以上的才可能有关联一说，单个元素的项集不存在关联问题\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            #该函数遍历L中的每一个频繁项集并对每个频繁项集创建只包含单个元素集合的列表H1\n",
    "            if (i > 1):\n",
    "            #如果频繁项集元素数目超过2,那么会考虑对它做进一步的合并\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:#第一层时，后件数为1\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)# 调用函数2\n",
    "    return bigRuleList\n",
    "\n",
    "#生成候选规则集合：计算规则的可信度以及找到满足最小可信度要求的规则\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    #针对项集中只有两个元素时，计算可信度\n",
    "    prunedH = []#返回一个满足最小可信度要求的规则列表\n",
    "    for conseq in H:#后件，遍历 H中的所有项集并计算它们的可信度值\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] #可信度计算，结合支持度数据\n",
    "        if conf >= minConf:\n",
    "            print (freqSet-conseq,'-->',conseq,'conf:',conf)\n",
    "            #如果某条规则满足最小可信度值,那么将这些规则输出到屏幕显示\n",
    "            brl.append((freqSet-conseq, conseq, conf))#添加到规则里，brl 是前面通过检查的 bigRuleList\n",
    "            prunedH.append(conseq)#同样需要放入列表到后面检查\n",
    "    return prunedH\n",
    "\n",
    "#合并\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    #参数:一个是频繁项集,另一个是可以出现在规则右部的元素列表 H\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)): #频繁项集元素数目大于单个集合的元素数\n",
    "        Hmp1 = aprioriGen(H, m+1)#存在不同顺序、元素相同的集合，合并具有相同部分的集合\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)#计算可信度\n",
    "        if (len(Hmp1) > 1):\n",
    "        #满足最小可信度要求的规则列表多于1,则递归来判断是否可以进一步组合这些规则\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'104'}) --> frozenset({'36'}) conf: 0.9650698602794411\n",
      "frozenset({'36'}) --> frozenset({'104'}) conf: 0.733131159969674\n",
      "frozenset({'38'}) --> frozenset({'36'}) conf: 0.9691720493247211\n",
      "frozenset({'36'}) --> frozenset({'38'}) conf: 0.834217841799343\n",
      "frozenset({'90'}) --> frozenset({'104'}) conf: 0.740029542097489\n",
      "frozenset({'104'}) --> frozenset({'90'}) conf: 1.0\n",
      "frozenset({'90'}) --> frozenset({'36'}) conf: 0.9741506646971935\n",
      "frozenset({'36'}) --> frozenset({'90'}) conf: 1.0\n",
      "frozenset({'90'}) --> frozenset({'38'}) conf: 0.8385032003938946\n",
      "frozenset({'38'}) --> frozenset({'90'}) conf: 1.0\n",
      "frozenset({'94'}) --> frozenset({'104'}) conf: 0.7334679454820798\n",
      "frozenset({'104'}) --> frozenset({'94'}) conf: 0.9667332002661344\n",
      "frozenset({'94'}) --> frozenset({'36'}) conf: 0.997728419989904\n",
      "frozenset({'36'}) --> frozenset({'94'}) conf: 0.9989891331817033\n",
      "frozenset({'94'}) --> frozenset({'38'}) conf: 0.8354366481574962\n",
      "frozenset({'38'}) --> frozenset({'94'}) conf: 0.9718144450968879\n",
      "frozenset({'94'}) --> frozenset({'90'}) conf: 1.0\n",
      "frozenset({'90'}) --> frozenset({'94'}) conf: 0.9753815854258986\n",
      "frozenset({'97'}) --> frozenset({'36'}) conf: 0.9743589743589743\n",
      "frozenset({'36'}) --> frozenset({'97'}) conf: 0.9219105382865808\n",
      "frozenset({'38'}) --> frozenset({'97'}) conf: 0.9489136817381092\n",
      "frozenset({'97'}) --> frozenset({'38'}) conf: 0.8632478632478632\n",
      "frozenset({'90'}) --> frozenset({'97'}) conf: 0.9217134416543574\n",
      "frozenset({'97'}) --> frozenset({'90'}) conf: 1.0\n",
      "frozenset({'94'}) --> frozenset({'97'}) conf: 0.9197375063099444\n",
      "frozenset({'97'}) --> frozenset({'94'}) conf: 0.9732905982905983\n",
      "frozenset({'90'}) --> frozenset({'97', '94'}) conf: 0.897095027080256\n",
      "frozenset({'97'}) --> frozenset({'90', '94'}) conf: 0.9732905982905983\n",
      "frozenset({'94'}) --> frozenset({'97', '90'}) conf: 0.9197375063099444\n",
      "frozenset({'94'}) --> frozenset({'97', '38'}) conf: 0.7915194346289752\n",
      "frozenset({'38'}) --> frozenset({'97', '94'}) conf: 0.920728126834997\n",
      "frozenset({'97'}) --> frozenset({'38', '94'}) conf: 0.8376068376068376\n",
      "frozenset({'90'}) --> frozenset({'97', '38'}) conf: 0.7956671590349581\n",
      "frozenset({'38'}) --> frozenset({'97', '90'}) conf: 0.9489136817381092\n",
      "frozenset({'97'}) --> frozenset({'38', '90'}) conf: 0.8632478632478632\n",
      "frozenset({'94'}) --> frozenset({'36', '97'}) conf: 0.9197375063099444\n",
      "frozenset({'97'}) --> frozenset({'36', '94'}) conf: 0.9732905982905983\n",
      "frozenset({'36'}) --> frozenset({'97', '94'}) conf: 0.9208996714682841\n",
      "frozenset({'90'}) --> frozenset({'38', '94'}) conf: 0.8148695224027572\n",
      "frozenset({'38'}) --> frozenset({'90', '94'}) conf: 0.9718144450968879\n",
      "frozenset({'94'}) --> frozenset({'38', '90'}) conf: 0.8354366481574962\n",
      "frozenset({'90'}) --> frozenset({'36', '97'}) conf: 0.8980797636632201\n",
      "frozenset({'97'}) --> frozenset({'36', '90'}) conf: 0.9743589743589743\n",
      "frozenset({'36'}) --> frozenset({'97', '90'}) conf: 0.9219105382865808\n",
      "frozenset({'90'}) --> frozenset({'36', '94'}) conf: 0.9731659281142294\n",
      "frozenset({'94'}) --> frozenset({'36', '90'}) conf: 0.997728419989904\n",
      "frozenset({'36'}) --> frozenset({'90', '94'}) conf: 0.9989891331817033\n",
      "frozenset({'90'}) --> frozenset({'104', '94'}) conf: 0.7154111275233875\n",
      "frozenset({'94'}) --> frozenset({'104', '90'}) conf: 0.7334679454820798\n",
      "frozenset({'104'}) --> frozenset({'90', '94'}) conf: 0.9667332002661344\n",
      "frozenset({'38'}) --> frozenset({'36', '97'}) conf: 0.920728126834997\n",
      "frozenset({'97'}) --> frozenset({'36', '38'}) conf: 0.8376068376068376\n",
      "frozenset({'36'}) --> frozenset({'97', '38'}) conf: 0.7925195855446044\n",
      "frozenset({'94'}) --> frozenset({'36', '38'}) conf: 0.8331650681474003\n",
      "frozenset({'38'}) --> frozenset({'36', '94'}) conf: 0.9691720493247211\n",
      "frozenset({'36'}) --> frozenset({'38', '94'}) conf: 0.834217841799343\n",
      "frozenset({'90'}) --> frozenset({'36', '38'}) conf: 0.8126538650910882\n",
      "frozenset({'38'}) --> frozenset({'36', '90'}) conf: 0.9691720493247211\n",
      "frozenset({'36'}) --> frozenset({'38', '90'}) conf: 0.834217841799343\n",
      "frozenset({'94'}) --> frozenset({'36', '104'}) conf: 0.7311963654719839\n",
      "frozenset({'104'}) --> frozenset({'36', '94'}) conf: 0.9637391882900864\n",
      "frozenset({'36'}) --> frozenset({'104', '94'}) conf: 0.7321202931513773\n",
      "frozenset({'90'}) --> frozenset({'36', '104'}) conf: 0.7141802067946824\n",
      "frozenset({'104'}) --> frozenset({'36', '90'}) conf: 0.9650698602794411\n",
      "frozenset({'36'}) --> frozenset({'104', '90'}) conf: 0.733131159969674\n",
      "frozenset({'104', '90'}) --> frozenset({'36', '94'}) conf: 0.9637391882900864\n",
      "frozenset({'90', '94'}) --> frozenset({'36', '104'}) conf: 0.7311963654719839\n",
      "frozenset({'104', '94'}) --> frozenset({'36', '90'}) conf: 0.9969029593943565\n",
      "frozenset({'36', '90'}) --> frozenset({'104', '94'}) conf: 0.7321202931513773\n",
      "frozenset({'36', '104'}) --> frozenset({'90', '94'}) conf: 0.9986211651154774\n",
      "frozenset({'36', '94'}) --> frozenset({'104', '90'}) conf: 0.7328611181381229\n",
      "frozenset({'90'}) --> frozenset({'36', '104', '94'}) conf: 0.7131954702117184\n",
      "frozenset({'104'}) --> frozenset({'36', '90', '94'}) conf: 0.9637391882900864\n",
      "frozenset({'94'}) --> frozenset({'36', '104', '90'}) conf: 0.7311963654719839\n",
      "frozenset({'36'}) --> frozenset({'104', '90', '94'}) conf: 0.7321202931513773\n",
      "frozenset({'90', '94'}) --> frozenset({'36', '38'}) conf: 0.8331650681474003\n",
      "frozenset({'38', '90'}) --> frozenset({'36', '94'}) conf: 0.9691720493247211\n",
      "frozenset({'38', '94'}) --> frozenset({'36', '90'}) conf: 0.9972809667673717\n",
      "frozenset({'36', '90'}) --> frozenset({'38', '94'}) conf: 0.834217841799343\n",
      "frozenset({'36', '94'}) --> frozenset({'38', '90'}) conf: 0.8350619782443715\n",
      "frozenset({'36', '38'}) --> frozenset({'90', '94'}) conf: 1.0\n",
      "frozenset({'90'}) --> frozenset({'36', '38', '94'}) conf: 0.8126538650910882\n",
      "frozenset({'94'}) --> frozenset({'36', '38', '90'}) conf: 0.8331650681474003\n",
      "frozenset({'38'}) --> frozenset({'36', '90', '94'}) conf: 0.9691720493247211\n",
      "frozenset({'36'}) --> frozenset({'90', '38', '94'}) conf: 0.834217841799343\n",
      "frozenset({'97', '90'}) --> frozenset({'36', '38'}) conf: 0.8376068376068376\n",
      "frozenset({'38', '90'}) --> frozenset({'36', '97'}) conf: 0.920728126834997\n",
      "frozenset({'97', '38'}) --> frozenset({'36', '90'}) conf: 0.9702970297029703\n",
      "frozenset({'36', '90'}) --> frozenset({'97', '38'}) conf: 0.7925195855446044\n",
      "frozenset({'36', '97'}) --> frozenset({'38', '90'}) conf: 0.8596491228070176\n",
      "frozenset({'36', '38'}) --> frozenset({'97', '90'}) conf: 0.9500151469251741\n",
      "frozenset({'90'}) --> frozenset({'36', '97', '38'}) conf: 0.7720334810438207\n",
      "frozenset({'97'}) --> frozenset({'36', '38', '90'}) conf: 0.8376068376068376\n",
      "frozenset({'38'}) --> frozenset({'36', '97', '90'}) conf: 0.920728126834997\n",
      "frozenset({'36'}) --> frozenset({'97', '38', '90'}) conf: 0.7925195855446044\n",
      "frozenset({'97', '94'}) --> frozenset({'36', '38'}) conf: 0.8605927552140504\n",
      "frozenset({'97', '38'}) --> frozenset({'36', '94'}) conf: 0.9702970297029703\n",
      "frozenset({'38', '94'}) --> frozenset({'36', '97'}) conf: 0.9474320241691843\n",
      "frozenset({'36', '97'}) --> frozenset({'38', '94'}) conf: 0.8596491228070176\n",
      "frozenset({'36', '94'}) --> frozenset({'97', '38'}) conf: 0.793321527953453\n",
      "frozenset({'36', '38'}) --> frozenset({'97', '94'}) conf: 0.9500151469251741\n",
      "frozenset({'97'}) --> frozenset({'36', '38', '94'}) conf: 0.8376068376068376\n",
      "frozenset({'94'}) --> frozenset({'36', '97', '38'}) conf: 0.7915194346289752\n",
      "frozenset({'38'}) --> frozenset({'36', '97', '94'}) conf: 0.920728126834997\n",
      "frozenset({'36'}) --> frozenset({'97', '38', '94'}) conf: 0.7925195855446044\n",
      "frozenset({'97', '90'}) --> frozenset({'36', '94'}) conf: 0.9732905982905983\n",
      "frozenset({'90', '94'}) --> frozenset({'36', '97'}) conf: 0.9197375063099444\n",
      "frozenset({'97', '94'}) --> frozenset({'36', '90'}) conf: 1.0\n",
      "frozenset({'36', '90'}) --> frozenset({'97', '94'}) conf: 0.9208996714682841\n",
      "frozenset({'36', '97'}) --> frozenset({'90', '94'}) conf: 0.9989035087719298\n",
      "frozenset({'36', '94'}) --> frozenset({'97', '90'}) conf: 0.9218315203642803\n",
      "frozenset({'90'}) --> frozenset({'36', '97', '94'}) conf: 0.897095027080256\n",
      "frozenset({'97'}) --> frozenset({'36', '90', '94'}) conf: 0.9732905982905983\n",
      "frozenset({'94'}) --> frozenset({'36', '97', '90'}) conf: 0.9197375063099444\n",
      "frozenset({'36'}) --> frozenset({'90', '97', '94'}) conf: 0.9208996714682841\n",
      "frozenset({'97', '90'}) --> frozenset({'38', '94'}) conf: 0.8376068376068376\n",
      "frozenset({'90', '94'}) --> frozenset({'97', '38'}) conf: 0.7915194346289752\n",
      "frozenset({'97', '94'}) --> frozenset({'38', '90'}) conf: 0.8605927552140504\n",
      "frozenset({'38', '90'}) --> frozenset({'97', '94'}) conf: 0.920728126834997\n",
      "frozenset({'97', '38'}) --> frozenset({'90', '94'}) conf: 0.9702970297029703\n",
      "frozenset({'38', '94'}) --> frozenset({'97', '90'}) conf: 0.9474320241691843\n",
      "frozenset({'97'}) --> frozenset({'90', '38', '94'}) conf: 0.8376068376068376\n",
      "frozenset({'90'}) --> frozenset({'97', '38', '94'}) conf: 0.7720334810438207\n",
      "frozenset({'94'}) --> frozenset({'97', '38', '90'}) conf: 0.7915194346289752\n",
      "frozenset({'38'}) --> frozenset({'90', '97', '94'}) conf: 0.920728126834997\n",
      "frozenset({'90', '97', '94'}) --> frozenset({'36', '38'}) conf: 0.8605927552140504\n",
      "frozenset({'97', '38', '90'}) --> frozenset({'36', '94'}) conf: 0.9702970297029703\n",
      "frozenset({'97', '38', '94'}) --> frozenset({'36', '90'}) conf: 1.0\n",
      "frozenset({'90', '38', '94'}) --> frozenset({'36', '97'}) conf: 0.9474320241691843\n",
      "frozenset({'36', '97', '90'}) --> frozenset({'38', '94'}) conf: 0.8596491228070176\n",
      "frozenset({'36', '97', '94'}) --> frozenset({'38', '90'}) conf: 0.8605927552140504\n",
      "frozenset({'36', '90', '94'}) --> frozenset({'97', '38'}) conf: 0.793321527953453\n",
      "frozenset({'36', '97', '38'}) --> frozenset({'90', '94'}) conf: 1.0\n",
      "frozenset({'36', '38', '90'}) --> frozenset({'97', '94'}) conf: 0.9500151469251741\n",
      "frozenset({'36', '38', '94'}) --> frozenset({'97', '90'}) conf: 0.9500151469251741\n",
      "frozenset({'97', '90'}) --> frozenset({'36', '38', '94'}) conf: 0.8376068376068376\n",
      "frozenset({'97', '94'}) --> frozenset({'36', '38', '90'}) conf: 0.8605927552140504\n",
      "frozenset({'90', '94'}) --> frozenset({'36', '97', '38'}) conf: 0.7915194346289752\n",
      "frozenset({'97', '38'}) --> frozenset({'36', '90', '94'}) conf: 0.9702970297029703\n",
      "frozenset({'38', '90'}) --> frozenset({'36', '97', '94'}) conf: 0.920728126834997\n",
      "frozenset({'38', '94'}) --> frozenset({'36', '97', '90'}) conf: 0.9474320241691843\n",
      "frozenset({'36', '97'}) --> frozenset({'90', '38', '94'}) conf: 0.8596491228070176\n",
      "frozenset({'36', '90'}) --> frozenset({'97', '38', '94'}) conf: 0.7925195855446044\n",
      "frozenset({'36', '94'}) --> frozenset({'97', '38', '90'}) conf: 0.793321527953453\n",
      "frozenset({'36', '38'}) --> frozenset({'90', '97', '94'}) conf: 0.9500151469251741\n",
      "frozenset({'97'}) --> frozenset({'36', '38', '94', '90'}) conf: 0.8376068376068376\n",
      "frozenset({'90'}) --> frozenset({'36', '38', '94', '97'}) conf: 0.7720334810438207\n",
      "frozenset({'94'}) --> frozenset({'36', '38', '97', '90'}) conf: 0.7915194346289752\n",
      "frozenset({'38'}) --> frozenset({'36', '94', '97', '90'}) conf: 0.920728126834997\n",
      "frozenset({'36'}) --> frozenset({'38', '94', '97', '90'}) conf: 0.7925195855446044\n",
      "耗时：0.4121859073638916秒\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataSet = loadDataSet()\n",
    "    dataSet = dataSet.values\n",
    "    dataSet = dataSet.tolist()\n",
    "    t1 = time()\n",
    "    L, suppData = apriori(dataSet, minSupport=0.7)\n",
    "    rules = generateRules(L, suppData, minConf=0.7)\n",
    "    t2 = time()\n",
    "    time = t2 - t1\n",
    "    print(f\"耗时：{time}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori algorithm\n",
    "\n",
    "https://github.com/guoziqingbupt/Apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**算法流程:**\n",
    "\n",
    "第1步： 生成1项集的集合C1。\n",
    "\n",
    "第2步： 寻找频繁1项集。\n",
    "\n",
    "第3步： 连接，作用就是用两个频繁k−1项集，组成一个k项集。\n",
    "\n",
    "第4步： 剪枝。剪枝的原理就是定理4，经过剪枝，现在Ck进一步缩减，这个过程也叫**子集测试**。\n",
    "\n",
    "第5步： 扫描事务数据库。做进一步筛选。扫描事务数据库D，找到所有事务中的项集的所有子集，找出在现在的Ck里面的子集，计数，这样能统计出来目前Ck当中的所有项集的频数，删去小于min_sup的，得到频繁k项集组成的集合Lk。\n",
    "\n",
    "第6步： 重复进行3，4，5步，直到找出的k项集Ck=∅.\n",
    "\n",
    "**函数的功能说明:**\n",
    "\n",
    "- `find_frequent_1_itemsets(D, min_sup)`:\n",
    "遍历D，根据min_sup找出所有的频繁1项集，结果记为L1，L1是列表型，且其每个元素都是一个长度为1的列表。用于上面第1，2步，找出频繁1项集。\n",
    "\n",
    "- `isLinkable(l1, l2)`:\n",
    "l1, l2为列表型，这个函数的作用是判断两个排好序的项集l1, l2是否是可连接的，用于上面第3步，连接的前提判断。\n",
    "\n",
    "- `gen_ksub1_subsets(s)`:\n",
    "生成集合s的所有长度为k - 1的子集，s为列表型，生成的结果为列表型，且结果的每个元素为列表型。这个函数用于上面第4步——剪枝，判断是否一个k项集的所有k - 1项子集都是频繁的\n",
    "\n",
    "- `subsets(S)`:\n",
    "求出集合S的所有子集，S为列表型，求出的结果result是一个列表，result的每个元素也是列表型，代表S的一个子集。这个函数用于上面第5步的筛选，求出每个事务的子集时用。\n",
    "\n",
    "- `apriori_gen(L_k_subtract_1)`:\n",
    "实现连接和剪枝两步，参数 `L_k_subtract_1`表示频繁k−1项集的集合\n",
    "\n",
    "- `subSetTest`:\n",
    "做子集测试，也就是剪枝的过程，调用了函数`has_infrequent_subset`检查每个子集的频繁与否\n",
    "\n",
    "- `subsets()`:\n",
    "求子集的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aprioriGen.py\n",
    "\n",
    "import copy\n",
    "\n",
    "def apriori_gen(L_k_subtract_1):\n",
    "    \"\"\"\n",
    "    There are 2 steps in apriori_gen:\n",
    "    1. link: execute l1 x l2, generate original Ck;\n",
    "    2. prune: delete the candidate in Ck who has infrequent subset\n",
    "    :param L_k_subtract_1: a list, each element is k-1 frequent itemset\n",
    "    :return: a semi-finished k itemset candidates Lk\n",
    "    \"\"\"\n",
    "\n",
    "    index1 = 0\n",
    "    k = len(L_k_subtract_1[0]) + 1\n",
    "    Ck = []\n",
    "\n",
    "    # while: link process\n",
    "    while index1 < len(L_k_subtract_1):\n",
    "\n",
    "        # the itemset l1 that to be linked: l1 x l2\n",
    "        l1 = L_k_subtract_1[index1]\n",
    "\n",
    "        # traverse L(k - 1), find the other itemset l2\n",
    "        for l2 in L_k_subtract_1[index1 + 1:]:\n",
    "\n",
    "            if isLinkable(l1, l2):\n",
    "\n",
    "                newItemSet = [item for item in l1[:k - 2]]\n",
    "\n",
    "                # add tail element with order\n",
    "                if l1[k - 2] < l2[k - 2]:\n",
    "                    newItemSet.append(l1[k - 2])\n",
    "                    newItemSet.append(l2[k - 2])\n",
    "                else:\n",
    "                    newItemSet.append(l2[k - 2])\n",
    "                    newItemSet.append(l1[k - 2])\n",
    "\n",
    "                Ck.append(newItemSet)\n",
    "\n",
    "        index1 += 1\n",
    "\n",
    "    # subSetTest: prune process\n",
    "    return subSetTest(Ck, L_k_subtract_1)\n",
    "\n",
    "\n",
    "def isLinkable(l1, l2):\n",
    "    \"\"\"\n",
    "    :param l1: a list\n",
    "    :param l2: a list\n",
    "    :return: if l1 and l2 is linkable\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(l1)\n",
    "\n",
    "    for index in range(n - 1):\n",
    "        if l1[index] != l2[index]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def subSetTest(Ck, L_k_subtract_1):\n",
    "    \"\"\"\n",
    "    prune process: according to apriori, test if every itemset in Ck is possible frequent\n",
    "    :param Ck: a list, and each element is also a list\n",
    "    :param L_k_subtract_1: a list, and each element is also a list\n",
    "    :return: a semi-finished Lk\n",
    "    \"\"\"\n",
    "\n",
    "    # the cur itemset that to be tested.\n",
    "    cur = 0\n",
    "    n = len(Ck)\n",
    "\n",
    "    semi_finished_Lk = []\n",
    "    while cur < n:\n",
    "\n",
    "        # testItemSet: a list\n",
    "        testItemSet = Ck[cur]\n",
    "\n",
    "        if not has_infrequent_subset(testItemSet, L_k_subtract_1):\n",
    "            semi_finished_Lk.append(testItemSet)\n",
    "\n",
    "        cur += 1\n",
    "\n",
    "    return semi_finished_Lk\n",
    "\n",
    "\n",
    "def has_infrequent_subset(testItemSet, L_k_subtract_1):\n",
    "    \"\"\"\n",
    "    :param testItemSet: the candidate k itemset, is a list\n",
    "    :param L_k_subtract_1: a list\n",
    "    :return: testItemSet has a infrequent subset or not\n",
    "    \"\"\"\n",
    "\n",
    "    for testSubSet in gen_ksub1_subsets(testItemSet):\n",
    "        if testSubSet not in L_k_subtract_1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def gen_ksub1_subsets(s):\n",
    "    \"\"\"\n",
    "    get all k - 1 subsets of s\n",
    "    :param s: a list, represents a itemset\n",
    "    :return: a list, represents k - 1 subsets\n",
    "    \"\"\"\n",
    "\n",
    "    index = 0\n",
    "    k = len(s)\n",
    "\n",
    "    result = []\n",
    "    while index < k:\n",
    "\n",
    "        exceptEle = s[index]\n",
    "        temp = copy.deepcopy(s)\n",
    "        temp.remove(exceptEle)\n",
    "\n",
    "        result.append(temp)\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## frequentCount.py\n",
    "\n",
    "##import copy\n",
    "\n",
    "def find_frequent_1_itemsets(D, min_sup):\n",
    "    \"\"\"\n",
    "    :param D: a dictionary, represents the whole transaction database\n",
    "    :param min_sup: the minimum support count\n",
    "    :return: a list L1, the collection of frequent 1 sets, and each element is a list\n",
    "    \"\"\"\n",
    "\n",
    "    L1 = []\n",
    "    C1 = {}\n",
    "\n",
    "    for TID in D:\n",
    "\n",
    "        for item in D[TID]:\n",
    "            if item not in C1:\n",
    "                C1[item] = 1\n",
    "            else:\n",
    "                C1[item] += 1\n",
    "\n",
    "    for itemset in C1:\n",
    "        if C1[itemset] >= min_sup:\n",
    "            L1.append([itemset])\n",
    "\n",
    "    return L1\n",
    "\n",
    "\n",
    "def subsets(S):\n",
    "    \"\"\"\n",
    "    find all subsets of set S, each subset is ordered\n",
    "    :param S: a list\n",
    "    :return: a list, and each element is a list\n",
    "    \"\"\"\n",
    "    S.sort()\n",
    "\n",
    "    path = []\n",
    "    step = 0\n",
    "    result = []\n",
    "\n",
    "    dfs(S, path, step, result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def dfs(S, path, step, result):\n",
    "    n = len(S)\n",
    "    if step == n:\n",
    "        temp = copy.deepcopy(path)\n",
    "        result.append(temp)\n",
    "        return\n",
    "\n",
    "    dfs(S, path, step + 1, result)\n",
    "    path.append(S[step])\n",
    "    dfs(S, path, step + 1, result)\n",
    "    path.pop()\n",
    "\n",
    "\n",
    "def scanDataBase(D, min_sup, semi_finished_Lk):\n",
    "    \"\"\"\n",
    "    scan the transaction database, filter the infrequent itemset\n",
    "    :param D: a dictionary, represents the whole transaction database\n",
    "    :param min_sup:\n",
    "    :param semi_finished_Lk: a list, represents semi_finished itemset Lk\n",
    "    :return: the final frequent itemset Lk\n",
    "    \"\"\"\n",
    "\n",
    "    Lk = []\n",
    "    k = len(semi_finished_Lk)\n",
    "    counts = [0 for i in range(len(semi_finished_Lk))]\n",
    "\n",
    "    for TID in D:\n",
    "\n",
    "        subSets = subsets(D[TID])\n",
    "\n",
    "        for subSet in subSets:\n",
    "\n",
    "            if subSet in semi_finished_Lk:\n",
    "                counts[semi_finished_Lk.index(subSet)] += 1\n",
    "\n",
    "    index = 0\n",
    "    while index < k:\n",
    "        if counts[index] >= min_sup:\n",
    "            Lk.append(semi_finished_Lk[index])\n",
    "        index += 1\n",
    "    return Lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## readData.py\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "def readData(fileName):\n",
    "    \"\"\"\n",
    "    read the csv data into a dictionary\n",
    "    :param fileName:\n",
    "    :return: a dictionary, as form as {TID: [items list]}\n",
    "    \"\"\"\n",
    "\n",
    "    with open(fileName) as csvFile:\n",
    "\n",
    "        reader = csv.reader(csvFile)\n",
    "\n",
    "        transactions = {}\n",
    "\n",
    "        for line in reader:\n",
    "\n",
    "            ID = line[0]\n",
    "            itemList = []\n",
    "\n",
    "            for item in line[1:]:\n",
    "                itemList.append(item)\n",
    "\n",
    "            transactions[ID] = itemList\n",
    "\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D:事务数据库，用字典的形式表示。键为TID，值为事务中出现的项的集合，这个集合以列表的形式存储。形式如`{TID: [I1, I2]}`\n",
    "\n",
    "`min_sup`:最小支持度计数阈值，int型，代码中，设定为2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I1'], ['I2'], ['I5'], ['I4'], ['I3'], ['I1', 'I2'], ['I1', 'I5'], ['I1', 'I3'], ['I2', 'I5'], ['I2', 'I4'], ['I2', 'I3'], ['I1', 'I2', 'I5'], ['I1', 'I2', 'I3']]\n"
     ]
    }
   ],
   "source": [
    "## main.py\n",
    "\n",
    "#import readData\n",
    "#from frequentCount import *\n",
    "#from aprioriGen import *\n",
    "\n",
    "min_sup = 2\n",
    "D = readData(\"./datasets/apriori/shoppingList.csv\")\n",
    "\n",
    "\n",
    "def miningFrequentItemSet(D, min_sup):\n",
    "\n",
    "    # initialized\n",
    "    frequentItemSets = []\n",
    "    L1 = find_frequent_1_itemsets(D, min_sup)\n",
    "    frequentItemSets.extend(L1)\n",
    "\n",
    "    # find frequent itemset Lk, until it is empty\n",
    "    Lk = L1\n",
    "    while len(Lk) != 0:\n",
    "\n",
    "        # here, Ck is also a semi-finished Lk which processed by link and prune\n",
    "        Ck = apriori_gen(Lk)\n",
    "\n",
    "        # obtain final frequent itemset Lk\n",
    "        Lk = scanDataBase(D, min_sup, Ck)\n",
    "\n",
    "        frequentItemSets.extend(Lk)\n",
    "\n",
    "    return frequentItemSets\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(miningFrequentItemSet(D, min_sup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
